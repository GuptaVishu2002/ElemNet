{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAE on Proposed Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re, os\n",
    "import math\n",
    "import operator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Contains 86 elements (Without Noble elements as it does not forms compounds in normal condition)\n",
    "elements = ['H','Li','Be', 'B', 'C', 'N', 'O', 'F', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'Cl',\n",
    "            'K', 'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe','Co', 'Ni', 'Cu', 'Zn', 'Ga', 'Ge',\n",
    "            'As', 'Se', 'Br', 'Kr', 'Rb', 'Sr', 'Y', 'Zr', 'Nb', 'Mo', 'Tc', 'Ru', 'Rh', 'Pd',\n",
    "            'Ag', 'Cd', 'In', 'Sn', 'Sb', 'Te', 'I', 'Xe', 'Cs', 'Ba', 'La', 'Ce', 'Pr', 'Nd',\n",
    "            'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er','Tm', 'Yb', 'Lu', 'Hf', 'Ta', 'W', \n",
    "            'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg', 'Tl', 'Pb', 'Bi', 'Ac', 'Th', 'Pa', 'U', 'Np', 'Pu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regex to Choose from Element Name, Number and Either of the Brackets\n",
    "token = re.compile('[A-Z][a-z]?|\\d+|[()]')\n",
    "\n",
    "# Create a dictionary with the Name of the Element as Key and No. of elements as Value\n",
    "def count_elements(formula):\n",
    "    tokens = token.findall(formula)\n",
    "    stack = [[]]\n",
    "    for t in tokens:\n",
    "        if t.isalpha():\n",
    "            last = [t]\n",
    "            stack[-1].append(t)\n",
    "        elif t.isdigit():\n",
    "             stack[-1].extend(last*(int(t)-1))\n",
    "        elif t == '(':\n",
    "            stack.append([])\n",
    "        elif t == ')':\n",
    "            last = stack.pop()\n",
    "            stack[-1].extend(last)   \n",
    "    return dict(Counter(stack[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalize the Value of the Dictionary\n",
    "def normalize_elements(dictionary):\n",
    "    factor=1.0/sum(dictionary.values())\n",
    "    for k in dictionary:\n",
    "        dictionary[k] = dictionary[k]*factor\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Optional Function\n",
    "def vectorize_elements(dictionary):\n",
    "    keys = np.array(list(dictionary.keys()))\n",
    "    values = np.array(list(dictionary.values()))\n",
    "    vector_elem = np.vstack((keys, values)).T\n",
    "    return vector_elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'H': 1391, 'F': 2086, 'Mg': 5, 'As': 5, 'Cl': 20, 'Br': 120, 'I': 120, 'Na': 20, 'Cs': 5}\n"
     ]
    }
   ],
   "source": [
    "#Check Making of the dictionary\n",
    "elem = count_elements(\"HF(Mg(H2F3)2As(H2F3)3(Cl((H2F3)3(Br(H2F3)4I)2)3Na)4Cs(H2F3)2)5\")\n",
    "print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'H': 0.36876988335100747, 'F': 0.5530222693531284, 'Mg': 0.001325556733828208, 'As': 0.001325556733828208, 'Cl': 0.005302226935312832, 'Br': 0.03181336161187699, 'I': 0.03181336161187699, 'Na': 0.005302226935312832, 'Cs': 0.001325556733828208}\n"
     ]
    }
   ],
   "source": [
    "#Check the normalization of the values\n",
    "norm_elem = normalize_elements(elem)\n",
    "print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List of compound as input\n",
    "compounds = ['HF(Mg(H2F3)2As(H2F3)3(Cl((H2F3)3(Br(H2F3)4I)2)3Na)4Cs(H2F3)2)5','Ca3(Co(CO3)3)2']\n",
    "\n",
    "#Make Dictionary out of the list of compound\n",
    "compounds = [count_elements(x) for x in compounds]\n",
    "\n",
    "#Normalize the value of dictionary\n",
    "compounds = [normalize_elements(x) for x in compounds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pre-process the dictionary to create a vector to make it suitable as an input for the DNN\n",
    "in_elements = np.zeros(shape=(len(compounds), len(elements)))\n",
    "comp_no = 0\n",
    "\n",
    "for compound in compounds:\n",
    "    keys = compound.keys()\n",
    "    for key in keys:\n",
    "        in_elements[comp_no][elements.index(key)] = compound[key]\n",
    "    comp_no+=1  \n",
    "    \n",
    "data = in_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import training data \n",
    "def load_data(csvname):\n",
    "    # load in data\n",
    "    data = np.asarray(pd.read_csv(csvname))\n",
    "\n",
    "    # import data and reshape appropriately\n",
    "    X = data[:,0:-1]\n",
    "    y = data[:,-1]\n",
    "    y.shape = (len(y),1)\n",
    "    \n",
    "    # pad data with ones for more compact gradient computation\n",
    "    #o = np.ones((np.shape(X)[0],1))\n",
    "    #X = np.concatenate((o,X),axis = 1)\n",
    "    #X = X.T\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert(lst): \n",
    "    res_dct = {lst[i]: lst[i + 1] for i in range(0, len(lst), 2)} \n",
    "    return res_dct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "separate = re.compile('[A-Z][a-z]?|\\d+\\.\\d')\n",
    "\n",
    "def correction(x_train):\n",
    "    new_x = []\n",
    "    for i in range (0,x_train.shape[0]):\n",
    "        new_x.append(separate.findall(x_train[i][0])) \n",
    "    new_x = np.asarray(new_x)\n",
    "    new_x.shape = (len(new_x),1)    \n",
    "    dict_x = convert(new_x[0][0])\n",
    "    input_x = []\n",
    "    for i in range (0,new_x.shape[0]):\n",
    "        input_x.append(convert(new_x[i][0]))\n",
    "        \n",
    "    in_elements = np.zeros(shape=(len(input_x), len(elements)))\n",
    "    comp_no = 0\n",
    "\n",
    "    for compound in input_x:\n",
    "        keys = compound.keys()\n",
    "        for key in keys:\n",
    "            in_elements[comp_no][elements.index(key)] = compound[key]\n",
    "        comp_no+=1  \n",
    "\n",
    "    data = in_elements    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, y_train = load_data('train_set.csv')\n",
    "x_test, y_test = load_data('test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_x_train = correction(x_train)\n",
    "new_x_test = correction(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_y_train = y_train\n",
    "new_y_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_y_train.shape = (len(new_y_train),)\n",
    "new_y_test.shape = (len(new_y_test),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elemnet_model():\n",
    "\t# create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, activation='relu', input_dim=86))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    #model.add(Dropout(0.2))(training=True)\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    #model.add(Dropout(0.1)(training=True))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    #model.add(Dropout(0.3)(training=True))\n",
    "    #model.add(Dropout(0.3))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    #model.add(Dropout(0.2)(training=True))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "\t# Compile model\n",
    "    adam = optimizers.Adam(lr=0.0001)\n",
    "    model.compile(loss=tf.keras.losses.mean_absolute_error, optimizer=adam, metrics=['mean_absolute_error'])\n",
    "    return model\n",
    "# build the model\n",
    "model = elemnet_model()\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "# Fit the model\n",
    "model.fit(new_x_train, new_y_train,verbose=2, validation_data=(new_x_test, new_y_test), epochs=1000, batch_size=32, callbacks=[es])\n",
    "y_predict = model.predict(new_x_test)\n",
    "f = open( 'resultElemNet.txt', 'w' )\n",
    "f.write(y_predict)\n",
    "f.close()\n",
    "model.save_weights(\"model1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
